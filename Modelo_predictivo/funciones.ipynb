{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97ea1f1-07b5-4a41-b6b8-fb3fc0050696",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac137a5-e454-48e0-a448-74cf5b3cd389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Básicos:\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Guardaro y carga de archivos:\n",
    "import json\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Preprocesamiento:\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Cross validation:\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modelos:\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Metricas:\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Extra:\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd63c2d-40ae-4280-9367-dd855955914a",
   "metadata": {},
   "source": [
    "# 1. Funciones de preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fab9d05-20e9-465c-b790-0cb44228b684",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.1. Filtrado y eliminación de valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e57a2d-7a20-4295-bbe4-8eed1b966a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_mascara(df):\n",
    "    \n",
    "    df[\"comunidad\"] = df[\"comunidad\"].str.replace(\"Catalunya\", \"Cataluña\").replace(\"Andalusia\", \"Andalucía\").replace(\"Euskadi\", \"País Vasco\")\n",
    "    \n",
    "    lista_comunidades = [\"Región de Bruselas-Capital\", \"Distrito de Lisboa\", \"Jalisco\", \"State of Rio Grande do Sul\", \"Inglaterra\", \"Hanói\", \"Hồ Chí Minh\", \"Maryland\", \"Bogotá\", \"Baden-Wurtemberg\", \"Baja Sajonia\", \"Renania del Norte-Westfalia\"]\n",
    "    comunidades_mask = df[\"comunidad\"].isin(lista_comunidades)\n",
    "    df= df[~comunidades_mask]\n",
    "    \n",
    "    mask = (df[\"jornada\"] == \"no especificado\") | (df[\"tipo_contrato\"] == \"no especificado\") | (df[\"herramientas\"] == \"set()\")\n",
    "    df_filtrado = df[~mask].dropna()\n",
    "    df_filtrado = df_filtrado.reset_index(drop= True)\n",
    "    \n",
    "    return df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49f36d-d5b2-4a19-8890-c25bfb4728e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.2. Agrupación de categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf48df9-4db5-479d-8c2d-ffe54cadfbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupador_categorias(df):\n",
    "    \n",
    "    # Tipo de contrato\n",
    "    tipos_contrato = [\"indefinido\", \"temporal\", \"practicas\"]\n",
    "    df[\"tipo_contrato\"] = df[\"tipo_contrato\"].apply(lambda x: \"otros contratos\" if x not in tipos_contrato else x)\n",
    "    \n",
    "    # Jornada\n",
    "    jornadas = [\"jornada completa\", \"practicas\", \"media jornada\"]    \n",
    "    df[\"jornada\"] = df[\"jornada\"].apply(lambda x: \"otras jornadas\" if x not in jornadas else x)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa521ae-c8cb-4b1c-b559-e72955080918",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.3. Encoding a las columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7483df93-1f48-4bcd-ad57-51ec37fb5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_encoder(df, encoder, ruta_encoders):\n",
    "    \n",
    "    encoded_columns = [\"jornada\", \"tipo_contrato\", \"comunidad\", \"categoria_empleo\"]\n",
    "    for num, columna in enumerate(encoded_columns):\n",
    "        \n",
    "        data_encoded = encoder.fit_transform(df[[columna]]).toarray()\n",
    "            \n",
    "        with open(ruta_encoders + f\"{num}_{columna}_encoder.pickle\", 'wb') as archivo:\n",
    "            pickle.dump(encoder, archivo)\n",
    "            \n",
    "        df_encoded = pd.DataFrame(data_encoded, columns= encoder.categories_)\n",
    "        df = pd.concat([df, df_encoded], axis=1).drop([columna], axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57478334-a56d-437d-8924-ee795cf146ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_encoder(df, encoder, ruta_encoders):\n",
    "    \n",
    "    data_encoded = encoder.fit_transform(df['herramientas'])\n",
    "\n",
    "    with open(ruta_encoders + \"4_tool_encoder.pickle\", 'wb') as archivo:\n",
    "        pickle.dump(encoder, archivo)\n",
    "\n",
    "    df_encoded = pd.DataFrame(data_encoded, columns= encoder.classes_)    \n",
    "    df = pd.concat([df, df_encoded], axis=1).drop(['herramientas'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b1c99-2be1-4644-86e5-5b772b1ade00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.4. Tratamiento de outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d307a1-fdb2-4690-aa75-47653d209332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodo_tukey(df, columna, alfa):\n",
    "    q1 = df[columna].quantile(0.25)\n",
    "    q3 = df[columna].quantile(0.75)\n",
    "    riq = q3 - q1\n",
    "\n",
    "    df_sin_out = df[df[columna].between(q1 - alfa * riq, q3 + alfa * riq) | (df[columna].isna())]\n",
    "    \n",
    "    return df_sin_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22faac95-3194-45e1-9ced-1d6d5e84cd46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1.5. Función de preparación de datos para modelado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22449a81-ea57-4757-9106-a1c6524f9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparator(df, rutas, encoders, log_transf= True):\n",
    "    \n",
    "    ########################### Rutas #######################################################\n",
    "    \n",
    "    ruta_listas = rutas[0]\n",
    "    ruta_encoders = rutas[1]\n",
    "    \n",
    "    ########################### Selección y limpieza de variables ###########################\n",
    "    \n",
    "    df_mod = df.drop(['titulo', 'empresa', 'fecha', 'descripcion','presencialidad', 'solicitudes', 'portal', 'localidad', 'provincia', 'pais', 'latitud', 'longitud'], axis= 1)\n",
    "    df_mod = aplicar_mascara(df_mod)\n",
    "    \n",
    "    ########################### Agrupo categoricas ##########################################\n",
    "    \n",
    "    df_mod = agrupador_categorias(df_mod)\n",
    "    \n",
    "    ########################### Limpio columna herrramientas ################################\n",
    "    \n",
    "    df_mod['herramientas'] = df_mod['herramientas'].apply(lambda x: re.sub(r\"[{}']\", '', x).split(', '))\n",
    "    \n",
    "    ########################### Obtengo listas ##############################################\n",
    "    \n",
    "    lista_herramientas = []\n",
    "    for herramientas in df_mod['herramientas']:\n",
    "        lista_herramientas.extend(herramientas)\n",
    "    lista_herramientas = set(lista_herramientas)\n",
    "    \n",
    "    lista_jornadas    = [jornada for jornada in df_mod[\"jornada\"].unique()]\n",
    "    \n",
    "    lista_experiencia = [exp for exp in range(df_mod[\"experiencia\"].min(), df_mod[\"experiencia\"].max() + 1)]\n",
    "    \n",
    "    lista_contratos   = [contrato for contrato in df_mod[\"tipo_contrato\"].unique()]\n",
    "    \n",
    "    lista_beneficios  = [True, False]\n",
    "    \n",
    "    lista_comunidades = [comunidad for comunidad in df_mod[\"comunidad\"].unique()]\n",
    "    \n",
    "    lista_categorias  = [categoria for categoria in df_mod[\"categoria_empleo\"].unique()]\n",
    "    \n",
    "    dic_listas = {\"herramientas\": list(lista_herramientas),\n",
    "                  \"jornada\"     : list(lista_jornadas),\n",
    "                  \"experiencia\" : list(lista_experiencia),\n",
    "                  \"contrato\"    : list(lista_contratos),\n",
    "                  \"beneficios\"  : list(lista_beneficios),\n",
    "                  \"comunidades\" : list(lista_comunidades),\n",
    "                  \"categorias\"  : list(lista_categorias)        \n",
    "                 }\n",
    "    ruta_guardado = os.path.join(ruta_listas, \"listas.json\")\n",
    "\n",
    "    # Guardar el diccionario como un archivo JSON\n",
    "    with open(ruta_guardado, 'w') as archivo:\n",
    "        json.dump(dic_listas, archivo)\n",
    "    \n",
    "    ########################### Encoding columnas categoricas ###############################\n",
    "    \n",
    "    encoder_columnas = encoders[0]\n",
    "    df_mod = column_encoder(df_mod, encoder_columnas, ruta_encoders)\n",
    "    \n",
    "    encoder_herramientas = encoders[1]\n",
    "    df_mod = tool_encoder(df_mod, encoder_herramientas, ruta_encoders)\n",
    "    \n",
    "    ########################### Elimino outliers del salario maximo y minimo ##################\n",
    "    \n",
    "    df_mod = metodo_tukey(df_mod, \"salario_min\", 1.5)\n",
    "    df_mod = metodo_tukey(df_mod, \"salario_max\", 1.5)\n",
    "    \n",
    "    ########################### Transformación logarítmica salario maximo y minimo ############\n",
    "    \n",
    "    df_mod[\"salario_min\"] = df_mod[\"salario_min\"].apply(np.log)\n",
    "    df_mod[\"salario_max\"] = df_mod[\"salario_max\"].apply(np.log)\n",
    "    #df_mod[\"experiencia\"] = df_mod[\"experiencia\"].apply(lambda x: np.log(x+1))\n",
    "    \n",
    "    ########################### Limpio nombre columnas ########################################\n",
    "    \n",
    "    df_mod.columns = [str(columna).replace(\"('\", \"\").replace(\"',)\", \"\") for columna in df_mod.columns]\n",
    "    \n",
    "    ########################### Separo dataframes #############################################\n",
    "    \n",
    "    # Salario mínimo    \n",
    "    df_salario_min = df_mod.drop([\"salario_max\"], axis= 1)\n",
    "    # Salario máximo\n",
    "    df_salario_max = df_mod.drop([\"salario_min\"], axis= 1)\n",
    "    \n",
    "    return df_salario_min, df_salario_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed435af-c203-4c00-8474-b49c22eff598",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Funciones de modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c88798-a94e-4c5f-ace5-2cb71c91e242",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1. Función de testeo de modelos de regresión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7758d395-2ca5-4a4a-a3f1-8fe4b7dba420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_tester(modelos, X, y, save= False):\n",
    "    \n",
    "    model_cross_holdout = []\n",
    "    \n",
    "    for modelo in modelos:\n",
    "\n",
    "        r2_score_results, mean_squared_error_results, mean_absolute_error_results = [], [], []\n",
    "\n",
    "        for i in range(20):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "            modelo.fit(X_train, y_train)\n",
    "            y_pred = modelo.predict(X_test)\n",
    "\n",
    "            r2_score_results.append(r2_score(y_test, y_pred))\n",
    "            mean_squared_error_results.append(mean_squared_error(y_test, y_pred))\n",
    "            mean_absolute_error_results.append(mean_absolute_error(y_test, y_pred))\n",
    "            \n",
    "\n",
    "        model_cross_holdout.append([str(modelo).split(\"(\")[0],\n",
    "                                    np.array(r2_score_results).mean(),\n",
    "                                    np.array(mean_squared_error_results).mean(),\n",
    "                                    np.array(mean_absolute_error_results).mean()\n",
    "                                   ])\n",
    "        \n",
    "    \n",
    "\n",
    "    df_cross_holdout = pd.DataFrame(model_cross_holdout, columns= [\"nombre\", \"mean_r2\", \"mean_MSE\", \"mean_MAE\"])\n",
    "    \n",
    "    if save:\n",
    "        nombre_archivo = input(\"Introduce el nombre del archivo: \")\n",
    "        df_cross_holdout.to_csv(f\"{nombre_archivo}.csv\", index= False, sep= \",\")\n",
    "    \n",
    "    return df_cross_holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea1fe4-59a1-44d8-a617-070670e9c1b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.2. Función de tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632efec3-a293-4d37-a36a-1a4af4aa1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tunning(modelo, parametros, X_train, X_test, y_train, y_test, salario, save= False):\n",
    "    \n",
    "    resultados = []\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator  = modelo,\n",
    "                               param_grid = parametros,\n",
    "                               scoring    = \"neg_mean_squared_error\",\n",
    "                               cv         = 5,\n",
    "                               refit      = True,\n",
    "                               n_jobs     = -1,  # Use all available processors\n",
    "                               verbose    = 2)\n",
    "\n",
    "    model_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Mejor modelo:\n",
    "    best_model = model_result.best_estimator_\n",
    "    params_best_model = best_model.get_params()\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Metricas:\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    resultados.append([str(modelo).split(\"(\")[0], best_model, params_best_model, r2, MAE, MSE])\n",
    "    df_resultados = pd.DataFrame(resultados, columns= [\"Nombre\", \"Modelo\", \"Parametros\",\"r2_score\", \"MAE\", \"MSE\"])\n",
    "    \n",
    "    if save:\n",
    "        df_resultados.to_csv(f\"salario_tuning_{salario}.csv\", index= \"False\", sep= \",\")\n",
    "        dump(best_model, f'{salario}_model.pkl')\n",
    "    \n",
    "    return df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54aaf0c-b9ac-4b18-b201-bd9e194cf1c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2.3. Función de testeo mejores PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c785c89d-7c1d-4017-bb0e-34c080d964b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_tester(salarios, modelos_svr, X_sal, y_sal):\n",
    "    resultados_PCA = []\n",
    "\n",
    "    for salario, modelo_svr, X, y in zip(salarios, modelos_svr, X_sal, y_sal):\n",
    "\n",
    "        resultados = []\n",
    "        for componentes in range(2, X.shape[1]):\n",
    "\n",
    "            pca = PCA(componentes, random_state=42)\n",
    "            X_pca = pca.fit_transform(X)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "            modelo_svr.fit(X_train, y_train)\n",
    "            y_pred = modelo_svr.predict(X_test)\n",
    "\n",
    "            # Métricas:\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            MAE = mean_absolute_error(y_test, y_pred)\n",
    "            MSE = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "            if r2 > 0.46:\n",
    "                resultados.append([salario, componentes, r2, MAE, MSE])\n",
    "\n",
    "        resultados_PCA.extend(resultados)\n",
    "\n",
    "    df_resultados_PCA = pd.DataFrame(resultados_PCA, columns= [\"salario\", \"componentes\", \"R2\", \"MAE\", \"MSE\"])\n",
    "    \n",
    "    return df_resultados_PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1db3b0d-b78f-4971-b9d7-dd7685d3187f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. Pipeline transformación de datos de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a972a0-9c81-4b00-8573-960499aca64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_transformer(X, ruta_encoders, ruta_modelos):\n",
    "    \n",
    "    #################################### Cargo encoders ###########################################\n",
    "    \n",
    "    encoders = [archivo for archivo in os.listdir(ruta_encoders) if archivo.endswith('.pickle')]\n",
    "\n",
    "    encoders_cargados = {}\n",
    "    for encoder in encoders:\n",
    "        ruta_encoder = os.path.join(ruta_encoders, encoder)\n",
    "\n",
    "        with open(ruta_encoder, 'rb') as file:\n",
    "            encoders_cargados[encoder] = pickle.load(file)\n",
    "            \n",
    "    ###############################################################################################\n",
    "    \n",
    "    #################################### Encoding a las columnas ##################################\n",
    "    \n",
    "    encoded_columns = [\"jornada\", \"tipo_contrato\", \"comunidad\", \"categoria_empleo\", \"herramientas\"]\n",
    "    \n",
    "    for columna, encoder in zip(encoded_columns, encoders_cargados.values()):\n",
    "        \n",
    "        if columna == \"herramientas\":\n",
    "            data_encoded = encoder.transform(X[columna])\n",
    "            df_encoded = pd.DataFrame(data_encoded, columns= encoder.classes_)    \n",
    "            X = pd.concat([X, df_encoded], axis=1).drop([columna], axis=1)            \n",
    "            \n",
    "        else:            \n",
    "            data_encoded = encoder.transform(X[[columna]]).toarray()\n",
    "            df_encoded = pd.DataFrame(data_encoded, columns= encoder.categories_)\n",
    "            X = pd.concat([X, df_encoded], axis=1).drop([columna], axis=1)\n",
    "    \n",
    "    #################################### Limpio nombre columnas ####################################\n",
    "    \n",
    "    X.columns = [str(columna).replace(\"('\", \"\").replace(\"',)\", \"\") for columna in X.columns]\n",
    "    \n",
    "    #################################### Transformación PCA ########################################\n",
    "    \n",
    "    with open(ruta_modelos + \"pca_min.pickle\", 'rb') as file:\n",
    "        pca_min = pickle.load(file)\n",
    "        \n",
    "    with open(ruta_modelos + \"pca_max.pickle\", 'rb') as file:\n",
    "        pca_max = pickle.load(file)\n",
    "        \n",
    "    X_pca_min = pca_min.transform(X)\n",
    "    X_pca_max = pca_max.transform(X)\n",
    "    \n",
    "    return X_pca_min, X_pca_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585fe7a-5176-498a-a7a4-4d1f4c126370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
