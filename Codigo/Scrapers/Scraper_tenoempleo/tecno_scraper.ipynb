{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41e97ba3-5c75-4798-9644-d98bbb63640f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73289dd-b46a-47fe-b135-8c1fc25f3d63",
   "metadata": {},
   "source": [
    "# Inicializar parametros de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28821d-5406-41cc-b211-8eb37a9d8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PONER USER-AGENT PROPIO:\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\"\n",
    "\n",
    "# Options:\n",
    "opts = Options()\n",
    "opts.add_argument(\"--disable-extensions\")\n",
    "opts.add_argument(f\"User-Agent={user_agent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195abbe-25e0-4880-87d4-7da383d1068d",
   "metadata": {},
   "source": [
    "# Función que me devuelve el número de páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fc6c5b-4286-4763-8553-1420ceb2f610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inicializar(limite=1000, nuevos= True):\n",
    "\n",
    "    # Inicializo navegador:\n",
    "    browser = webdriver.Chrome(options=opts)\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    # Entro en tecnoempleo:\n",
    "    if nuevos:\n",
    "        url_paginas = f\"https://www.tecnoempleo.com/ofertas-trabajo/?ult_24h=,1,&pagina={limite}\"\n",
    "        \n",
    "    else:\n",
    "        url_paginas = f\"https://www.tecnoempleo.com/ofertas-trabajo/?pagina={limite}\"\n",
    "    \n",
    "    browser.get(url_paginas)\n",
    "    \n",
    "    # Acepto cookies\n",
    "    browser.find_elements(By.CLASS_NAME, \"col-6\")[0].click()\n",
    "    \n",
    "    # Saco el número de páginas\n",
    "    soup = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    num_paginas = int(soup.find(\"li\", class_= \"active\").text)\n",
    "    \n",
    "    return num_paginas    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dea7833-d101-43c2-a9ba-31fcd9e41a76",
   "metadata": {},
   "source": [
    "# Función de scrapeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5908aa0-07aa-45e9-b7d7-d0864ea0469c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iniciar_scraper(num_paginas, nuevos= True):\n",
    "    \n",
    "    portal = \"tecnoempleo\"\n",
    "    fecha_scrapeo = datetime.datetime.now().date()\n",
    "    \n",
    "    # Inicializo navegador:\n",
    "    browser = webdriver.Chrome(options=opts)\n",
    "    browser.maximize_window()\n",
    "    \n",
    "    datos_ofertas_empleo = []\n",
    "    \n",
    "    contador = 0\n",
    "    for pagina in range(num_paginas + 1):\n",
    "        \n",
    "        if nuevos:\n",
    "            tecno_url = f\"https://www.tecnoempleo.com/ofertas-trabajo/?ult_24h=,1,&pagina={pagina}\"\n",
    "        else:\n",
    "            tecno_url = f\"https://www.tecnoempleo.com/ofertas-trabajo/?pagina={pagina}\"\n",
    "\n",
    "        browser.get(tecno_url)\n",
    "        sleep(1)\n",
    "        \n",
    "        # Acepto cookies\n",
    "        try:\n",
    "            browser.find_elements(By.CLASS_NAME, \"col-6\")[0].click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Saco las urls de cada puesto ofertado y saco la información\n",
    "        soup_page = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "        ofertas_empleo = soup_page.find_all(\"div\", class_= \"col-10\")\n",
    "\n",
    "        for oferta in ofertas_empleo:\n",
    "\n",
    "            # URL oferta de empleo\n",
    "            url_oferta = oferta.find(\"a\")[\"href\"]\n",
    "            # Entro en la oferta\n",
    "            browser.get(url_oferta)\n",
    "            sleep(1)\n",
    "            # Saco información relevante de la oferta\n",
    "            soup_oferta = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "\n",
    "            lista_li = soup_oferta.find(\"ul\", class_= \"fs--15\").find_all(\"li\", class_= \"border-bottom\")\n",
    "\n",
    "            ubicacion, funciones, jornada, experiencia, tipo_contrato, salario = [np.nan] * 6\n",
    "            for li in lista_li:\n",
    "\n",
    "                tag = li.find(\"span\", class_= \"d-inline-block\").text\n",
    "\n",
    "                if tag == \"Ubicación\" : \n",
    "                    ubicacion = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "                elif tag == \"Funciones\":\n",
    "                    funciones = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "                elif tag == \"Jornada\":\n",
    "                    jornada = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "                elif tag == \"Experiencia\":\n",
    "                    experiencia = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "                elif tag == \"Tipo contrato\":\n",
    "                    tipo_contrato = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "                elif tag == \"Salario\":\n",
    "                    salario = li.find(\"span\", class_= \"float-end\").text.strip().replace(\"\\xa0\", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "            titulo = soup_oferta.find(\"div\", class_= \"col-lg-8\").find(\"h1\").text.replace(\"\\t\", \"\").replace(\"Urgente\\n\", \"\").strip()\n",
    "        \n",
    "            try:\n",
    "                empresa = soup_oferta.find(\"div\", class_= \"col-lg-8\").find(\"a\", class_= \"fs--18\").text.strip()\n",
    "            except:\n",
    "                empresa = np.nan\n",
    "\n",
    "            fecha = soup_oferta.find(\"div\", class_= \"col-lg-8\").find(\"span\", \"ml-4\").text.strip().replace(\"Actualizada\", \"\")\n",
    "\n",
    "            herramientas = soup_oferta.find(\"ul\", class_= \"fs--15\").find(\"li\", class_= \"mb-3\").text.strip().replace(\"\\n\", \", \")\n",
    "\n",
    "            descripcion = soup_oferta.find(\"div\", class_= \"mt-4\").text.replace(\"\\n\", \" \").replace(\"\\t\", \" \").replace(\"Descripción de la oferta de empleo\", \"\").strip()\n",
    "\n",
    "            datos_ofertas_empleo.append([titulo, empresa, fecha, herramientas, descripcion, ubicacion, funciones, jornada, experiencia, tipo_contrato, salario, fecha_scrapeo, url_oferta, portal])\n",
    "            \n",
    "        contador =+ 1\n",
    "        if contador % 2 == 0:\n",
    "            sleep(3)\n",
    "            \n",
    "    df = pd.DataFrame(datos_ofertas_empleo, columns= [\"titulo\", \"empresa\", \"fecha\", \"herramientas\", \"descripcion\", \"ubicacion\", \"funciones\", \"jornada\", \"experiencia\", \"tipo_contrato\", \"salario\", \"fecha_scrapeo\", \"url\", \"portal\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a3dc4-0c52-4ecd-ab1f-aeeb8de0b60c",
   "metadata": {},
   "source": [
    "# Inicializar WEB BROWSER y obtener número de páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6600feef-a851-4d48-a51c-14e46da27b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PONER USER-AGENT PROPIO:\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fb4d23-d477-4653-b6a1-8ac303f84d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_paginas = inicializar(user_agent)\n",
    "num_paginas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91eec1-fd1c-4bea-b2ba-d67d2135f756",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inicializar el Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d85dd450-34fc-4649-954a-ddf70c9c70aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = iniciar_scraper(num_paginas)\n",
    "\n",
    "# Lo guardo en la ruta de datos:\n",
    "fecha = datetime.datetime.now().strftime(\"%d-%m-%y\")\n",
    "ruta_datos = \"C:\\\\Users\\\\regue\\\\Desktop\\\\Data Science Projects\\\\PROJECTS\\\\IT_Job_Spain_Project\\\\Datos\\\\datos_sin_procesar\\\\\"\n",
    "nombre_archivo = f\"datos_tecnoempleo_{fecha}.csv\"\n",
    "ruta_completa = os.path.join(ruta_datos, nombre_archivo)\n",
    "\n",
    "df.to_csv(ruta_completa, index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
